<!DOCTYPE html>

<html>
    <head>
        <title>Projects</title>
        <!-- link to main stylesheet -->
        <link href="https://fonts.googleapis.com/css?family=Lato:300,400" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/css/main_1.css">
    </head>
    <body>

        <nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<!-- <li><a href="/about">About</a></li> -->
        		<li><a href="/assets/Pratyush_WPI_Resume.pdf">R‌&#233;sum‌&#233;</a></li>
        		<li><a href="/projects.html">Experience</a></li>
    		</ul>
		</nav>

        <h4> Research </h4>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          
          <tr>
              <td width="25%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Projects/wc.gif' style="width:240px;height:140px;">
                </div>
              </td>
              <td valign="top" width="75%">
                  <p>Semi-Autonomous Stairclimbing Wheelchair<br></p>
                  Yogita Choudhary,<a href="https://sites.google.com/view/nidhi-malhotra/home">Nidhi Malhotra<a>, Pratyush Kumar Sahoo<br> 
                <i>Indian Institute Of Technology, Varanasi</i><p2>   [Accepted for presentation at Student Design Competition, AIM Boston, 2020]</p2><br><br>          
                <p2>We  develop  a  low  cost  semi-autonomous,  robustmechanism  for  a  stair-climbing  wheelchair  in  this  work.  Thecore contribution is the system include the design of a variablegeometry track-based mechanism which accomplishes the taskof stair climbing. Additionally, for safety of the user we proposea mechanism to adjust the elevation of the seat through closed-loop   feedback   control.   For   attitude   estimation,   we   employthe  Extended  Kalman  Filter  Approach.  The  algorithm  fuses data   from   IMU,   RGB   and   Depth   channels   of   the   Kinectsensor. Presence of both RGB and Depth data helps to receivean  accurate  pose  estimate  is  different  lighting  conditions.The dynamics  of  the  robot  have  been  approximated  as  a  first-order linear system. A Proportional Integral (PI) Controller isimplemented  for  Heading  angle  control  to  maintain  a  desiredpath  of  the  wheelchair.  Slip  Compensation  is  done  using  theSlip  Compensated  Optometry  using  Gyro  approach.Finally,we  stress  test  our  algorithms  in  the  Robot  Operating  System(ROS) simulation software and prove that the algorithm worksefficiently in maintaining zero heading angle throughout ascend <a href="https://sites.google.com/itbhu.ac.in/sascw/home">[Project Page]</a> <a href="https://drive.google.com/file/d/1N-o31Qdj8-QFg7yBdQzoe6XPprs3yurg/view?usp=sharing">[Thesis]</a> <a href="https://ras.papercept.net/proceedings/AIM20/0505.pdf">[Poster]</a><br></p2>
              </td>
          </tr>
          <tr>

          <tr>
              <td width="25%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Projects/RRC.gif' style="width:240px;height:140px;">
                </div>
              </td>
              <td valign="top" width="75%">
                  <p>Monocular shape and Pose estimation of Indian Vechiles<br></p>
                  Pratyush Kumar Sahoo, Sarthak Sharma, <a href="http://robotics.iiit.ac.in/">K. Madhava Krishna</a><br>
                <i>Robotics Research Center, IIIT-H</i><p2> <br><br>
                <anchor id="p_swaayatt_stereo" href=''></anchor>
                <p2>We inspected and trained the stacked hourglass network for vehicle pose estimation(Buses) on a synthetic dataset generated by triangulation followed by bundle adjustment and RenderForCNN on 400 ShapeNet CAD Models. The network was trained on a CRF style loss function to force learn inter keypoint distances.<a href="https://drive.google.com/drive/folders/1XV85MA6hbrge5xRkuRC3Z_TPSXVUobYq?usp=sharing">[Results]</a> <a href="https://drive.google.com/file/d/1IJ_w6zC3ej91pZGiYAPBzQej_qwUpMV2/view?usp=sharing">[Report]</a>  <br></p2>
              </td>
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
              <!-- <div class="two"><img src='friendly_after.png'></div> -->
              <img src='/assets/Projects/inspirARM.gif' style="width:240px;height:200px;">
              </div>
            </td>
            <td valign="top" width="75%">
		    <p>InspirARM<br></p>
		    <i>Indian Institute Of Technology, Varanasi</i><p2>   [Presented at the Inter IIT TechMeet 8.0, Engineer's Conclave]</p2><br><br>
                <anchor id="p_research_calib" href=''></anchor>
              <br>
<!--               <i>inspirARM</i><p2></p2><br><br> -->
              <p2>Designed and 3D printed a robotic arm, used servo motors and arduino to control finger motions. Used an EMG sensor module on the user arm to collect signals and trained a neural network classifier to classify between 5 different hand motions. Later, integrated a raspberry pi camera and utilized a pre-trained mobile net object detection network to predict the most suitable grip depending upon the object detected.  <a href="https://drive.google.com/file/d/1HxiY80zw4ohZl5E_82bN7fj-AVmjWnfd/view?usp=sharing">[Poster]<a href="https://docs.google.com/presentation/d/1RVZQvA85_B3mUXlAERW7i2ZljiRgrNL3BUX1_1-z0aA/edit?usp=sharing">[Presentation]
              
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
              <!-- <div class="two"><img src='friendly_after.png'></div> -->
              <img src='/assets/Projects/frames_idetect_final.gif' style="width:240px;height:150px;">
              </div>
            </td>
            <td valign="top" width="75%">
		    <p>iDetect<br></p>
                <anchor id="p_research_calib" href=''></anchor>
              <br>
              <i>iVizz, cAST Technologies</i><p2> [Filed a Provisional US Patent]</p2><br><br>
              <p2>Utilized the work of <a href="https://arxiv.org/pdf/1812.08008.pdf">Zhe Cao et al</a> to build a human touch detection pipeline on 2D surveillance camera feeds. Created a custom pose classification deep neural network to differentiate between human postures taking pose points output from the first network as an input to eleminate false-positives. Showcased results on cluttered Indian Hospital environments. The entire application is deployed at <a href="https://www.ivizz-ai.com/index.html">iVizz</a>
              
          </tr>
		              <tr>
            <td width="25%">
              <div class="one">
              <!-- <div class="two"><img src='friendly_after.png'></div> -->
              <img src='/assets/Projects/AUV_Final.gif' style="width:240px;height:150px;">
              </div>
            </td>
            <td valign="top" width="75%">
		    <p>iDetect<br></p>
                <anchor id="p_research_calib" href=''></anchor>
              <br>
              <i>Swaayat</i><p2> Participated in  the SAUVC Competition</p2><br><br>
              <p2>Inspected and implemented image enhancement algorithms including Homomorphic filters and Contrast stretching on underwater images. Trained and finetuned <a href="https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/">Detectron-2</a> for underwater object detection and localization on the Robosub dataset. <a href="https://github.com/pks-97/imageEnhancement">[Image Enhancement]</a><a href="https://github.com/joeljosephjin/detectron2robosub">[Object Detection]</a><a href="https://drive.google.com/file/d/1rpU5nnRGUtGgkM5aF0ngCqYuphhm13rT/view?usp=sharing">[Concept Design Report]</a>
              
          </tr>
      </table>

      

      <footer>
          <a style="float: right; padding-top: 25px;" href="https://jonbarron.info/">Template Credits</a>
          <!-- <ul>
              <li><a href="mailto:giyer2309@gmail.com">email</a></li>
              <li><a href="https://github.com/epiception">github.com/epiception</a></li>
          </ul> -->
          <div class="footer-social-icons">
              <!-- <h4 class="_14">Follow us on</h4> -->
              <ul class="social-icons">
                  <li><a href="mailto:pratyushk.sahoo.min16@itbhu.ac.in" class="social-icon"> <i class="fa fa-envelope"></i></a></li>
<!--                   <li><a href="https://www.linkedin.com/in/ganesh-iyer-0607bb112/" class="social-icon"> <i class="fa fa-linkedin"></i></a></li>
                  <li><a href="https://github.com/epiception" class="social-icon"> <i class="fa fa-github"></i></a></li>
                  <li><a href="https://www.youtube.com/user/giyer2309/videos?view_as=subscriber&sort=dd&view=0&shelf_id=0" class="social-icon"> <i class="fa fa-youtube"></i></a></li> -->
              </ul>
          </div>
      </footer>
    </body>

</html>
